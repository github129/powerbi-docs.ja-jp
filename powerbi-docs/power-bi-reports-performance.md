---
title: Power BI のパフォーマンスのベスト プラクティス
description: この記事では、Power BI で高速で信頼性の高いレポートを作成するためのベスト プラクティスについて説明します。
author: MarkMcGeeAtAquent
ms.author: kfile
manager: kfile
ms.reviewer: ''
ms.service: powerbi
ms.subservice: powerbi-service
ms.topic: conceptual
ms.date: 05/18/2018
LocalizationGroup: Reports
ms.openlocfilehash: f603a733c6c604a89b0b9608904acdf13b66b713
ms.sourcegitcommit: c8c126c1b2ab4527a16a4fb8f5208e0f7fa5ff5a
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 01/15/2019
ms.locfileid: "54287786"
---
# <a name="power-bi-performance-best-practices"></a>Power BI のパフォーマンスのベスト プラクティス

この記事では、Power BI で高速で信頼性の高いレポートを作成するためのベスト プラクティスについて説明します。  

## <a name="use-filters-to-limit-report-visuals-to-display-only-whats-needed"></a>必要なものだけを表示するようにフィルターを使用してレポートのビジュアルを制限する 

ビジュアルで表示する必要のあるデータが増えるほど、ビジュアルの読み込みが遅くなります。 これは当然の原則であるように思われますが、忘れがちなことです。 たとえば、大規模なデータセットがあるとします。 その上に、テーブルのテーブルを使用してレポートを構築します。 エンド ユーザーはページ上でスライサーを使用して、必要な行に到達します。通常、エンド ユーザーが関心があるのは、数十の行だけです。

よくある間違いは、テーブルの既定のビューをフィルター処理しないことです。つまり、1 億行を超えるすべてが表示されます。 これらの行のデータは、メモリに読み込む必要があり、更新のたびに圧縮解除する必要があります。 これにより、大量のメモリ負荷が生じます。 解決策: "上位 N" フィルターを使用して、表示されるテーブルの項目の最大数を減らします。 項目の最大数は、ユーザーが必要な数より大幅に大きくする (10,000 など) ことができます。 その結果、エンド ユーザー エクスペリエンスを変えずに、レポートのメモリ使用率を大幅に減らし、それによってパフォーマンスが向上します。

レポートのすべてのビジュアルに対して、上記と同様のアプローチを行うことをお勧めします。 このビジュアルのデータはすべて必要かどうか、 エンドユーザー エクスペリエンスへの影響を最小限に抑え、ビジュアルに表示されるデータの量をフィルター処理して減らす方法がないかを確認してください。 特にテーブルが大量のメモリを消費する可能性があることに注意してください。

## <a name="limit-visuals-on-report-pages"></a>レポート ページのビジュアルを制限する

上記の原則は、特定のレポートでのビジュアルの数にも同様に当てはまります。 特定のレポートでのビジュアルの数を必要な分だけに制限することを強くお勧めします。 ドリル スルー ページは、レポートにさらに多くのビジュアルを詰め込むことなく、追加の詳細を提供する優れた方法です。  

## <a name="optimize-your-model"></a>モデルの最適化

ベスト プラクティス:

- 未使用のテーブルまたは列は、可能であれば削除します。 
- 高いカーディナリティ (数百万の独自の値) を持つフィールドでは重複しない値の数を避けます。  
- 不要な精度と高いカーディナリティを持つフィールドを回避する手順を実行します。 たとえば、非常に独特な datetime 値を月、年、日などの個別の列に分割できます。または、可能であれば、高精度のフィールドに丸め処理を使用して、カーディナリティを減らします (例: 13.29889 -> 13.3)。
- 可能な限り、文字列ではなく整数を使用します。
- テーブル内のすべての行をテストする必要がある DAX 関数 (RANKX など) に注意してください。最悪の場合、テーブル サイズで線形増加が指定されている場合、これらの関数によって実行時間とメモリ要件が指数関数的に増加する可能性があります。
- DirectQuery を使用してデータ ソースに接続する場合に、列のインデックス作成を検討します。これは通常、もう一度フィルター処理またはスライスされるため、レポートの応答性が大幅に改善されます。  

DirectQuery のデータ ソースの最適化の詳細については、「[DirectQuery in SQL Server 2016 Analysis Services](https://blogs.msdn.microsoft.com/analysisservices/2017/04/06/directquery-in-sql-server-2016-analysis-services-whitepaper/)」 (SQL Server 2016 Analysis Services の DirectQuery) を参照してください。

## <a name="directquery-and-live-connection-understand-underlying-data-source-performance"></a>DirectQuery とライブ接続: 基になるデータ ソースのパフォーマンスを理解する

DirectQuery やライブ接続の場合、ユーザーが Power BI レポートを閲覧すると、Power BI が基になるデータ ソースにリアルタイムにクエリを送信します。 データ ソースからクエリ データが返されると、レポートが表示されます。 その結果、このようなレポートのパフォーマンスは、基になるデータ ソースのパフォーマンスに大きく依存します。

このような場合、基になるデータ ソースのパフォーマンスを理解することが重要になります。 クエリのパフォーマンスを理解するためのツールは、データ ソースごとに異なります。 たとえば、SQL Server および Azure SQL では、クエリの履歴とそれらの実行時統計を取得するクエリ ストアが用意されています。

目安として、DirectQuery とライブ接続上に構築された Power BI レポートをデプロイするときに、エンドユーザーが Power BI Desktop で何をするかを試します。 Power BI Desktop でレポートの読み込みに時間がかかる場合は、エンド ユーザーのサービスでもほぼ確実に読み込みに時間がかかります。 

## <a name="directquery-best-practices"></a>DirectQuery のベスト プラクティス

次のセクションでは、DirectQuery を使用して接続するための一般的なベスト プラクティスについて説明します。
  
### <a name="db-design-guidance"></a>DB の設計のガイダンス

- 可能な場合は、計算列とメジャーをソースにプッシュします。ソースに近いほど、パフォーマンスが高くなります。
- 最適化します。 クエリの実行プランを理解したり、一般的にフィルター処理される列にインデックスを追加したりします。

### <a name="modeling-guidance"></a>モデリングのガイダンス

- Power BI Desktop で開始します。
- クエリ エディターで複雑なクエリを作成しないようにします。
- クエリ エディターで相対日付フィルターは使わないでください。  
- メジャーは、最初は単純にして、徐々に複雑さを追加します。
- 計算列と一意識別子列のリレーションシップは避けます。
- リレーションシップに [参照整合性を想定] を設定してみます。多くの場合、これでクエリのパフォーマンスを大幅に向上できます。  

### <a name="general"></a>全般

- 最初にフィルターを適用します。
- ビジュアル間の相互作用を無効にすることを検討します。これにより、ユーザーがクロス強調表示するときに、クエリの負荷を軽減できます。
- 上記で説明したように、ビジュアルとビジュアルごとのデータの数を制限します。
- 行レベルのセキュリティを有効にすると、パフォーマンスに大幅な変化が生じる場合があります。 必ず、ユーザーが想定するものと異なる行レベルのセキュリティ ロールをテストしてください。
- 時間のかかるクエリによってシステム リソースが独占されないようにするため、サービスによって適用されるクエリ レベルのタイムアウトがあります。 225 秒より長くかかるクエリはタイムアウトし、ビジュアル レベルのエラーが発生します。

## <a name="understand-dashboards-and-query-caches"></a>ダッシュボードとクエリ キャッシュを理解する

ダッシュボードにピン留めされたビジュアルは、ダッシュボードが読み込まれるときに、クエリ キャッシュによって提供されます。 逆に、レポートを閲覧したときに、データ ソース (インポートの場合は Power BI サービス、または DirectQuery やライブ接続の場合は指定したデータ ソースのどちらか) に対するクエリがその場で作成されます。  

> [!NOTE]
> ライブ レポート タイルをダッシュボードにピン留めするときに、これらのタイルはクエリ キャッシュから提供されるのではなく、レポートと同様に動作し、バックエンド コアに対してその場でクエリを作成します。

名前からわかるように、クエリ キャッシュからデータを取得することで、データ ソースに依存するよりも優れたより一貫性のあるパフォーマンスが実現できます。 この機能を活用するための 1 つの方法は、ダッシュボードをユーザーのための最初のランディング ページにすることです。 よく使用され、頻繁に要求されるビジュアルをダッシュボードにピン留めします。 こうすることで、ダッシュボードが貴重な "防御の最前線" となり、容量への負荷を抑え、一貫したパフォーマンスが実現できます。 ユーザーは引き続き、レポートをクリック スルーして詳細を調べることができます。  
 

DirectQuery とライブ接続では、このクエリ キャッシュはデータ ソースのクエリを実行することで定期的に更新されます。 既定ではこれは 1 時間ごとに行われますが、データセットの設定で構成できます。 各クエリ キャッシュの更新では、基になるデータ ソースにクエリを送信して、キャッシュを更新します。 生成されるクエリの数は、そのデータ ソースに依存するダッシュボードにピン留めされたビジュアルの数によって異なります。 行レベルのセキュリティが有効になっている場合は、異なるセキュリティ コンテキストごとにクエリが生成されることに注意してください。 たとえば、ユーザーが分類される 2 つの異なるロールと、2 つの異なるデータのビューがある場合、クエリ キャッシュの更新中に 2 セットのクエリが生成されます。 

## <a name="understand-custom-visual-performance"></a>カスタム ビジュアルのパフォーマンスを理解する 

高パフォーマンスを得るため、必ず各カスタム ビジュアルの性能を試します。 適切に最適化されていないカスタム ビジュアルは、レポート全体のパフォーマンスに悪影響を及ぼす場合があります。 

## <a name="deep-dive-into-query-performance-with-sql-profiler-and-power-bi-desktop"></a>SQL Profiler と Power BI Desktop でのクエリ パフォーマンスをさらに探究する

どのビジュアルが最も多くの時間とリソースを占有しているかをより深く調べるため、SQL Profiler を Power BI Desktop に接続して、クエリ パフォーマンスの全体像を得ることができます。

> [!NOTE]
> Power BI Desktop は、診断ポートへの接続をサポートします。 診断ポートは、その他のツールの接続と、診断目的のトレースの実行を可能にします。 *モデルに対する変更はサポートされていません。モデルに変更を加えると、破損とデータ損失が発生する可能性があります。*

手順は次のとおりです。
  
1. **SQL Server Profiler をインストールし、Power BI Desktop を実行する**

   SQL Server Profiler は、SQL Server Management Studio の一部として使用できます。

2. **Power BI Desktop で使用されているポートを決める**

   管理者特権でコマンド プロンプトまたは PowerShell を実行して、netstat を使用して Power BI Desktop が分析に使用しているポートを検索します。

   `> netstat -b -n`

   出力には、アプリケーションと、開いているポートの一覧が表示されます。次に例を示します。  

   `TCP    [::1]:55786            [::1]:55830            ESTABLISHED`

   [msmdsrv.exe]

   msmdsrv.exe で使用するポートを検索し、後で使用するために書きとめます。 この場合、ポート 55786 を使用します。
3. **SQL Server Profiler を Power BI Desktop に接続する**

   - **[スタート]** メニューから SQL Server Profiler を起動する
   - **[ファイル]** > **[新しいトレース]**
   - サーバーの種類:Analysis Services
   - サーバー名: localhost:[上記で見つかったポート番号]
   - 次の画面で、**[実行]** を選択
   - これで SQL Profiler がライブになり、Power BI Desktop が送信するクエリをアクティブにプロファイリングします。 
   - クエリが実行されると、クエリのそれぞれの期間および CPU 時間を表示できます。この情報を使用して、ボトルネックとなっているクエリを判断できます。  

SQL Profiler を使用すると、パフォーマンスのボトルネックとなる可能性の高い、CPU 時間が最も長いクエリを識別することができます。 これらのクエリを実行するビジュアルを、継続的な最適化の中心とする必要があります。

## <a name="gateway-best-practices"></a>ゲートウェイのベスト プラクティス

オンプレミスのデータ ゲートウェイは、Power BI サービスと自身のオンプレミスのデータを接続するための優れたツールです。 同時に、計画が不十分な場合には、レポートのパフォーマンスのボトルネックとなることもあります。 すべてのクエリとクエリの応答がゲートウェイを介して渡される DirectQuery/ライブ接続データセットの場合は、特にその傾向が高くなります。 高パフォーマンスのゲートウェイを確保するためのいくつかのベスト プラクティスを次に示します。 

- 個人用モードではなく、**エンタープライズ モードを使用**する。
- **ゲートウェイのハードウェアの推奨仕様**: 8 CPU コア、16 GB の RAM。
- **監視の設定**: ゲートウェイ マシンにパフォーマンスの監視を設定し、ゲートウェイが過負荷になり、ボトルネックとなっているかどうかを理解します。 詳細については、「[オンプレミス データ ゲートウェイのトラブルシューティング](service-gateway-onprem-tshoot.md)」をご覧ください。
- **スケール アップまたはスケール アウト**: ゲートウェイが実際にボトルネックとなっている場合は、スケール アップ (ゲートウェイをより多くの CPU と RAM が搭載されたより強力なコンピューターに移動する) またはスケール アウト (たとえば、データセットを別のゲートウェイに分割する) を検討してください。 
- **インポートとDirectQuery の分離**: スケール アウトする場合は、インポートを担当するゲートウェイと DirectQuery を担当するゲートウェイを分離することを検討します。

## <a name="network-latency"></a>ネットワーク待機時間

ネットワーク待機時間は、要求が Power BI サービスに到達するまでに要する時間と、応答の配信に要する時間が増えることで、レポートのパフォーマンスに影響を及ぼす可能性があります。 Power BI のテナントには、特定のリージョンが割り当てられています。 自分のテナントの "ホーム" 領域を表示するには、powerbi.com に移動して、右上にある [?] を選択し、**[Power BI について]** を選択します。 テナントのユーザーが Power BI サービスにアクセスすると、要求は常にこのリージョンにルーティングされます。 要求が Power BI サービスに到達すると、サービスが追加の要求を (基になるデータ ソースやゲートウェイなどに) 送信することがあり、これもネットワーク待機時間に影響します。

[Azure Speed Test](http://azurespeedtest.azurewebsites.net/) などのツールは、クライアントと Azure リージョン間のネットワーク待機時間の表示を提供できます。 一般に、ネットワーク待機時間の影響を最小限に抑えるには、データ ソース、ゲートウェイ、および Power BI クラスターをできるだけ近くに配置するようにします。 ネットワーク待機時間が問題の場合は、ゲートウェイとデータ ソースを仮想マシンに配置することで、Power BI クラスターにより近い位置に配置することができます。

ネットワークの待機時間をさらに改善するには、[Azure ExpressRoute](https://azure.microsoft.com/services/expressroute/) の使用を検討してください。これは、クライアントと Azure データ センター間により高速でより信頼性の高い接続を作成することができます。

## <a name="next-steps"></a>次の手順

- Power BI の大規模なデプロイに関する総合的なガイダンスを使用して、[Power BI Enterprise のデプロイを計画する](https://aka.ms/pbienterprisedeploy)
- [SQL Server 2016 Analysis Services の DirectQuery](https://blogs.msdn.microsoft.com/analysisservices/2017/04/06/directquery-in-sql-server-2016-analysis-services-whitepaper/)
- [[YouTube] Power BI で高速で信頼性の高いレポートを作成する](https://www.youtube.com/watch?v=GhiJABR7XX0)
- [[YouTube] Power BI Enterprise のデプロイ](https://www.youtube.com/watch?v=K-zEWICvICM)